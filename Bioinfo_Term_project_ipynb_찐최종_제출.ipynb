{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkAjFWlY9Rleijj7zHYJv5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunggu-Kim-SNU/SNU-bioinfo-hw-SG/blob/main/Bioinfo_Term_project_ipynb_%EC%B0%90%EC%B5%9C%EC%A2%85_%EC%A0%9C%EC%B6%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive 마운트\n",
        "\n",
        "개인 노트북에서 진행할 예정이지만 혹시 코랩에서 진행할 수도 있으니\n",
        "마운트"
      ],
      "metadata": {
        "id": "xzApa5eaNk_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-oZNLgQK0kj",
        "outputId": "e664bb25-3df6-4aa9-d2f8-db45ceffaefe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습용 Bioconda 환경 설치"
      ],
      "metadata": {
        "id": "dO7FYdQ_XBo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hyeshik/colab-biolab.git\n",
        "!cd colab-biolab && bash tools/setup.sh\n",
        "exec(open('colab-biolab/tools/activate_conda.py').read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTftnp7rXFKW",
        "outputId": "98fe405f-f1b4-463b-c947-2f3bf54df784"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'colab-biolab' already exists and is not an empty directory.\n",
            "./\n",
            "./root/\n",
            "./root/.bashrc.biolab\n",
            "./root/.tmux.conf\n",
            "./root/.bin.priority/\n",
            "./root/.bin.priority/pip2\n",
            "./root/.bin.priority/pip3\n",
            "./root/.bin.priority/pip\n",
            "./root/.profile\n",
            "./root/.condarc\n",
            "./root/.vimrc\n",
            "PREFIX=/root/conda\n",
            "Unpacking payload ...\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "entry_point.py:256: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /root/conda\n",
            "Activated conda environment `lab'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실습에 필요한 파일을 구글 드라이브에 다운로드"
      ],
      "metadata": {
        "id": "oI1qdk3XX5th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이것들 가 필요없네,,\n",
        "\n",
        "\n",
        "# GENECODE Annotation 데이터 다운로드 (필요 없는데 받았네,,,)\n",
        "\n",
        "#!wget --no-check-certificate -O /content/drive/MyDrive/term_project/gencode.gtf.gz http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M27/gencode.vM27.annotation.gtf.gz\n",
        "\n",
        "#!wget -O /content/drive/MyDrive/term_project/mouse_transcript.fa.gz http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M27/gencode.vM27.transcripts.fa.gz\n",
        "\n",
        "# Lin28a binding site 엑셀파일 다운로드를 하려고 했으나 권한이 없다고 해서 그냥 직접 넣음\n",
        "\n",
        "\n",
        "# RefSeq mRNA FASTA를 받아서 압축해제 후 병합\n",
        "\n",
        "#!wget -O /content/drive/MyDrive/term_project/mouse.1.rna.fna.gz http://ftp.ncbi.nlm.nih.gov/refseq/M_musculus/mRNA_Prot/mouse.1.rna.fna.gz\n",
        "#!wget -O /content/drive/MyDrive/term_project/mouse.2.rna.fna.gz http://ftp.ncbi.nlm.nih.gov/refseq/M_musculus/mRNA_Prot/mouse.2.rna.fna.gz\n",
        "#!wget -O /content/drive/MyDrive/term_project/mouse.3.rna.fna.gz http://ftp.ncbi.nlm.nih.gov/refseq/M_musculus/mRNA_Prot/mouse.3.rna.fna.gz\n",
        "\n",
        "#!gunzip /content/drive/MyDrive/term_project/mouse.1.rna.fna.gz\n",
        "#!gunzip /content/drive/MyDrive/term_project/mouse.2.rna.fna.gz\n",
        "#!gunzip /content/drive/MyDrive/term_project/mouse.3.rna.fna.gz\n",
        "\n",
        "#!cat mouse.1.rna.fna mouse.2.rna.fna mouse.3.rna.fna > /content/drive/MyDrive/term_project/mouse.all_rna.fasta\n",
        "\n",
        "#!head mouse.all_rna.fasta\n",
        "\n",
        "# 찐막,,,\n",
        "# UCSC FTP 서버 경로 설정\n",
        "#UCSC_FTP=\"ftp://hgdownload.soe.ucsc.edu/goldenPath/mm9/database\"\n",
        "\n",
        "## RefSeq annotation 파일 (2011년 8월 당시 mm9 기준 RefSeq)\n",
        "#!wget -O /content/drive/MyDrive/term_project/refGene.txt.gz ${UCSC_FTP}/refGene.txt.gz\n",
        "#!wget -O /content/drive/MyDrive/term_project/refMrna.fa.gz ${UCSC_FTP}/refMrna.fa.gz\n",
        "#!wget -O /content/drive/MyDrive/term_project/refLink.txt.gz ${UCSC_FTP}/refLink.txt.gz\n",
        "\n",
        "# 파일을 압축 해제\n",
        "#!gunzip /content/drive/MyDrive/term_project/refGene.txt.gz\n",
        "#!gunzip /content/drive/MyDrive/term_project/refMrna.fa.gz\n",
        "#!gunzip /content/drive/MyDrive/term_project/refLink.txt.gz\n",
        "\n",
        "# 찐찐막\n",
        "!wget -O /content/drive/MyDrive/term_project/refMrna.fa.gz http://hgdownload.soe.ucsc.edu/goldenPath/mm9/bigZips/refMrna.fa.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rO_4PDX7iNNA",
        "outputId": "e31729c4-f4c8-4864-a131-a9ab4202602b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-11 19:42:02--  http://hgdownload.soe.ucsc.edu/goldenPath/mm9/bigZips/refMrna.fa.gz\n",
            "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45684806 (44M) [application/x-gzip]\n",
            "Saving to: ‘/content/drive/MyDrive/term_project/refMrna.fa.gz’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]  43.57M  76.0MB/s    in 0.6s    \n",
            "\n",
            "2025-06-11 19:42:03 (76.0 MB/s) - ‘/content/drive/MyDrive/term_project/refMrna.fa.gz’ saved [45684806/45684806]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘 다운 되었는지 확인\n",
        "\n",
        "!ls -lh /content/drive/MyDrive/term_project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yVBRHs0m7jC",
        "outputId": "80a0b3a5-b5bc-4484-817a-f62d037f47d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 1.3G\n",
            "-rw------- 1 root root 2.4M Jun  2 04:18 binding_windows_-10+10.csv\n",
            "-rw------- 1 root root 843M May 31 18:33 gencode.gtf\n",
            "-rw------- 1 root root  11M May 31 18:22 Lin28a_binding.xls\n",
            "-rw------- 1 root root 647K Jun  2 04:48 mismatch_report.csv\n",
            "-rw------- 1 root root 252M Mar  9  2021 mouse_transcript.fa\n",
            "-rw------- 1 root root 126M Oct 17  2019 refMrna.fa\n",
            "-rw------- 1 root root  44M Oct 17  2019 refMrna.fa.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDeW-Sa0FeqG"
      },
      "outputs": [],
      "source": [
        "# GENECODE Annotation 데이터 압축해제\n",
        "\n",
        "#!gunzip /content/drive/MyDrive/term_project/gencode.gtf.gz\n",
        "\n",
        "# Transcript FASTA 파일 압축해제\n",
        "\n",
        "!gunzip /content/drive/MyDrive/term_project/refMrna.fa.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/drive/MyDrive/term_project/refMrna.fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu8L_wRf3GT_",
        "outputId": "2ce30c64-48e3-4a79-c07f-48d71aac87cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">NR_046233 2\n",
            "actgacacgctgtcctttccctattaacactaaaggacactataaagaga\n",
            "ccctttcgatttaaggctgttttgcttgtccagcctattctttttactgg\n",
            "cttgggtctgtcgcggtgcctgaagctgtccccgagccacgcttcctgct\n",
            "ttcccgggcttgctgcttgcgtgtgcttgctgtgggcagcttgtgacaac\n",
            "tgggcgctgtgactttgctgcgtgtcagacgtttttcccgatttccccga\n",
            "ggtgtcgttgtcacacctgtcccggttggaatggtggagccagctgtggt\n",
            "tgagggccaccttatttcggctcactttttttttttttttttctcttgga\n",
            "gtcccgaacctccgctcttttctcttcccggtctttcttccacatgcctc\n",
            "ccgagtgcatttctttttgttttttttctttttttttttttttttttggg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "binding site 주변 window sequence 뽑아내기 (-10~+10)"
      ],
      "metadata": {
        "id": "hWdrd0dHkHZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 설치\n",
        "\n",
        "!pip install biopython"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntRa0Cn2oWVX",
        "outputId": "2ab9cf77-e0cd-4647-c8a1-6744315a0a0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "\n",
        "# 경로 설정\n",
        "project_path = \"/content/drive/MyDrive/term_project/\"\n",
        "\n",
        "# .xls 파일 읽기\n",
        "binding_sites = pd.read_excel(f\"{project_path}Lin28a_binding.xls\", header=1)\n",
        "print(binding_sites.head())\n",
        "\n",
        "# transcript별 binding site 개수 세기\n",
        "site_counts = binding_sites[\"Transcript\"].value_counts()\n",
        "\n",
        "# 2개 이상인 transcript만 남김\n",
        "multi_site_transcripts = site_counts[site_counts >= 2].index\n",
        "\n",
        "# binding site가 1개뿐인 transcript 제거\n",
        "binding_sites = binding_sites[binding_sites[\"Transcript\"].isin(multi_site_transcripts)]\n",
        "\n",
        "# 전사체 서열 로드 (버전 제거한 ID만 저장)\n",
        "fasta_file = f\"{project_path}refMrna.fa\"\n",
        "transcripts = {}\n",
        "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "    fasta_id = record.description.split()[0]       # FASTA 첫 번째 단어 (ID)\n",
        "    fasta_id_short = fasta_id.split('.')[0]        # 버전 없는 ID\n",
        "    transcripts[fasta_id_short] = record.seq\n",
        "\n",
        "# -10~+10 window 추출\n",
        "windows = []\n",
        "for idx, row in binding_sites.iterrows():\n",
        "    transcript_id = row[\"Transcript\"]\n",
        "    transcript_id_short = transcript_id.split('.')[0]   # 버전 없는 ID로 비교\n",
        "\n",
        "    if transcript_id_short not in transcripts:\n",
        "        print(f\"[{idx}] {transcript_id} not found in FASTA\")\n",
        "        continue\n",
        "\n",
        "    pos = int(row[\"Position\"]) - 1   # 0-based index\n",
        "    seq = transcripts[transcript_id_short]\n",
        "    start = max(0, pos - 10)\n",
        "    end = min(len(seq), pos + 10 + 1)\n",
        "    window_seq = seq[start:end]\n",
        "\n",
        "    windows.append({\n",
        "        \"Transcript\": transcript_id,\n",
        "        \"Position\": row[\"Position\"],\n",
        "        \"WindowSeq\": str(window_seq)\n",
        "    })\n",
        "\n",
        "# 결과 저장\n",
        "output_file = f\"{project_path}binding_windows_-10+10.csv\"\n",
        "windows_df = pd.DataFrame(windows)\n",
        "windows_df.to_csv(output_file, index=False)\n",
        "print(\"완료! 저장 위치:\", output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDMzZ5CwkPD-",
        "outputId": "efc7cfb0-7b2e-46ca-d3ad-47f22d5fbc8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Transcript  Position    Gene Symbol Crosslinked base  \\\n",
            "0  NM_027855       808  0610007C21Rik                G   \n",
            "1  NM_027855       897  0610007C21Rik                G   \n",
            "2  NM_027854       278  0610007L01Rik                G   \n",
            "3  NM_027854       976  0610007L01Rik                G   \n",
            "4  NM_027854      1175  0610007L01Rik                G   \n",
            "\n",
            "   Number of detected libraries  Detection depth (35L33G)  \\\n",
            "0                             3                      84.0   \n",
            "1                             3                      39.0   \n",
            "2                             1                       NaN   \n",
            "3                             3                     268.0   \n",
            "4                             2                       NaN   \n",
            "\n",
            "   Score in entropy (35L33G)  Detection depth (2J3)  Score in entropy (2J3)  \\\n",
            "0                   1.092933                   89.0                0.912925   \n",
            "1                   0.698734                   81.0                1.002371   \n",
            "2                        NaN                   27.0                1.046562   \n",
            "3                   1.133825                  235.0                1.238238   \n",
            "4                        NaN                   53.0                0.867737   \n",
            "\n",
            "   Detection depth (polyclonal)  Score in entropy (polyclonal)  \n",
            "0                          99.0                       0.970821  \n",
            "1                          59.0                       0.734745  \n",
            "2                           NaN                            NaN  \n",
            "3                         272.0                       1.401739  \n",
            "4                          54.0                       0.505494  \n",
            "[461] NM_027285 not found in FASTA\n",
            "[462] NM_027285 not found in FASTA\n",
            "[463] NM_027285 not found in FASTA\n",
            "[464] NM_027285 not found in FASTA\n",
            "[465] NM_027285 not found in FASTA\n",
            "[466] NM_027285 not found in FASTA\n",
            "[467] NM_027285 not found in FASTA\n",
            "[468] NM_027285 not found in FASTA\n",
            "[469] NM_027285 not found in FASTA\n",
            "[470] NM_027285 not found in FASTA\n",
            "[471] NM_027285 not found in FASTA\n",
            "[472] NM_027285 not found in FASTA\n",
            "[473] NM_027285 not found in FASTA\n",
            "[474] NM_027285 not found in FASTA\n",
            "[475] NM_027285 not found in FASTA\n",
            "[476] NM_027285 not found in FASTA\n",
            "[477] NM_027285 not found in FASTA\n",
            "[478] NM_027285 not found in FASTA\n",
            "[479] NM_027285 not found in FASTA\n",
            "[480] NM_027285 not found in FASTA\n",
            "[963] NR_024619 not found in FASTA\n",
            "[964] NR_024619 not found in FASTA\n",
            "[965] NR_024619 not found in FASTA\n",
            "[1668] NR_033601 not found in FASTA\n",
            "[1669] NR_033601 not found in FASTA\n",
            "[1670] NR_033601 not found in FASTA\n",
            "[1811] NM_175017 not found in FASTA\n",
            "[1812] NM_175017 not found in FASTA\n",
            "[2036] NR_027360 not found in FASTA\n",
            "[2037] NR_027360 not found in FASTA\n",
            "[2038] NR_027360 not found in FASTA\n",
            "[8192] NM_001099628 not found in FASTA\n",
            "[8193] NM_001099628 not found in FASTA\n",
            "[8194] NM_001099628 not found in FASTA\n",
            "[8195] NM_001099628 not found in FASTA\n",
            "[8196] NM_001099628 not found in FASTA\n",
            "[8197] NM_001099628 not found in FASTA\n",
            "[8198] NM_001099628 not found in FASTA\n",
            "[8199] NM_001099628 not found in FASTA\n",
            "[8200] NM_001099628 not found in FASTA\n",
            "[8201] NM_001099628 not found in FASTA\n",
            "[8202] NM_001099628 not found in FASTA\n",
            "[8203] NM_001099628 not found in FASTA\n",
            "[8204] NM_001099628 not found in FASTA\n",
            "[8205] NM_001099628 not found in FASTA\n",
            "[8206] NM_001099628 not found in FASTA\n",
            "[8207] NM_001099628 not found in FASTA\n",
            "[8208] NM_001099628 not found in FASTA\n",
            "[8209] NM_001099628 not found in FASTA\n",
            "[8210] NM_001099628 not found in FASTA\n",
            "[8818] NM_144921 not found in FASTA\n",
            "[8819] NM_144921 not found in FASTA\n",
            "[8820] NM_144921 not found in FASTA\n",
            "[8821] NM_144921 not found in FASTA\n",
            "[8822] NM_144921 not found in FASTA\n",
            "[8823] NM_144921 not found in FASTA\n",
            "[8824] NM_144921 not found in FASTA\n",
            "[8825] NM_144921 not found in FASTA\n",
            "[8826] NM_144921 not found in FASTA\n",
            "[8827] NM_144921 not found in FASTA\n",
            "[8828] NM_144921 not found in FASTA\n",
            "[8829] NM_144921 not found in FASTA\n",
            "[8830] NM_144921 not found in FASTA\n",
            "[8831] NM_144921 not found in FASTA\n",
            "[8832] NM_144921 not found in FASTA\n",
            "[8833] NM_144921 not found in FASTA\n",
            "[9794] NM_177047 not found in FASTA\n",
            "[9795] NM_177047 not found in FASTA\n",
            "[9796] NM_177047 not found in FASTA\n",
            "[9797] NM_177047 not found in FASTA\n",
            "[10484] NM_001112729 not found in FASTA\n",
            "[10485] NM_001112729 not found in FASTA\n",
            "[11658] NM_001025387 not found in FASTA\n",
            "[11659] NM_001025387 not found in FASTA\n",
            "[11660] NM_001025387 not found in FASTA\n",
            "[11661] NM_001025387 not found in FASTA\n",
            "[11662] NM_001025387 not found in FASTA\n",
            "[11663] NM_001025387 not found in FASTA\n",
            "[11664] NM_001025387 not found in FASTA\n",
            "[11665] NM_001025387 not found in FASTA\n",
            "[11666] NM_001025387 not found in FASTA\n",
            "[11667] NM_001025387 not found in FASTA\n",
            "[11668] NM_001025387 not found in FASTA\n",
            "[11669] NM_001025387 not found in FASTA\n",
            "[12294] NM_001034857 not found in FASTA\n",
            "[12295] NM_001034857 not found in FASTA\n",
            "[12296] NM_001034857 not found in FASTA\n",
            "[12297] NM_001034857 not found in FASTA\n",
            "[12298] NM_001034857 not found in FASTA\n",
            "[12299] NM_001034857 not found in FASTA\n",
            "[12300] NM_001034857 not found in FASTA\n",
            "[12301] NM_001034857 not found in FASTA\n",
            "[12302] NM_001034857 not found in FASTA\n",
            "[12303] NM_001034857 not found in FASTA\n",
            "[12304] NM_001034857 not found in FASTA\n",
            "[12305] NM_001034857 not found in FASTA\n",
            "[12306] NM_001034857 not found in FASTA\n",
            "[12307] NM_001034857 not found in FASTA\n",
            "[12308] NM_001034857 not found in FASTA\n",
            "[12309] NM_001034857 not found in FASTA\n",
            "[12310] NM_001034857 not found in FASTA\n",
            "[12311] NM_001034857 not found in FASTA\n",
            "[12495] NM_029755 not found in FASTA\n",
            "[12496] NM_029755 not found in FASTA\n",
            "[12497] NM_029755 not found in FASTA\n",
            "[12498] NM_029755 not found in FASTA\n",
            "[12628] NM_001115076 not found in FASTA\n",
            "[12629] NM_001115076 not found in FASTA\n",
            "[12630] NM_001115076 not found in FASTA\n",
            "[12631] NM_001115076 not found in FASTA\n",
            "[12632] NM_001115076 not found in FASTA\n",
            "[12633] NM_001115076 not found in FASTA\n",
            "[12634] NM_001115076 not found in FASTA\n",
            "[12635] NM_001115076 not found in FASTA\n",
            "[12636] NM_001115076 not found in FASTA\n",
            "[12637] NM_001115076 not found in FASTA\n",
            "[12638] NM_001081360 not found in FASTA\n",
            "[12639] NM_001081360 not found in FASTA\n",
            "[12640] NM_001081360 not found in FASTA\n",
            "[12641] NM_001081360 not found in FASTA\n",
            "[12642] NM_001081360 not found in FASTA\n",
            "[12643] NM_001081360 not found in FASTA\n",
            "[12644] NM_001081360 not found in FASTA\n",
            "[12645] NM_001081360 not found in FASTA\n",
            "[12646] NM_001081360 not found in FASTA\n",
            "[12647] NM_001081360 not found in FASTA\n",
            "[12648] NM_001081360 not found in FASTA\n",
            "[12649] NM_001081360 not found in FASTA\n",
            "[12650] NM_001081360 not found in FASTA\n",
            "[12651] NM_001081360 not found in FASTA\n",
            "[12652] NM_001081360 not found in FASTA\n",
            "[12653] NM_001081360 not found in FASTA\n",
            "[12654] NM_001081360 not found in FASTA\n",
            "[12655] NM_001081360 not found in FASTA\n",
            "[15359] NM_027429 not found in FASTA\n",
            "[15360] NM_027429 not found in FASTA\n",
            "[15361] NM_027429 not found in FASTA\n",
            "[15986] NM_001081417 not found in FASTA\n",
            "[15987] NM_001081417 not found in FASTA\n",
            "[15988] NM_001081417 not found in FASTA\n",
            "[15989] NM_001081417 not found in FASTA\n",
            "[15990] NM_001081417 not found in FASTA\n",
            "[15991] NM_001081417 not found in FASTA\n",
            "[15992] NM_001081417 not found in FASTA\n",
            "[15993] NM_001081417 not found in FASTA\n",
            "[15994] NM_001081417 not found in FASTA\n",
            "[15995] NM_001081417 not found in FASTA\n",
            "[15996] NM_001081417 not found in FASTA\n",
            "[15997] NM_001081417 not found in FASTA\n",
            "[15998] NM_001081417 not found in FASTA\n",
            "[15999] NM_001081417 not found in FASTA\n",
            "[16465] NM_001081276 not found in FASTA\n",
            "[16466] NM_001081276 not found in FASTA\n",
            "[16467] NM_001081276 not found in FASTA\n",
            "[16468] NM_001081276 not found in FASTA\n",
            "[16469] NM_001081276 not found in FASTA\n",
            "[16470] NM_001081276 not found in FASTA\n",
            "[16471] NM_001081276 not found in FASTA\n",
            "[16472] NM_001081276 not found in FASTA\n",
            "[16473] NM_001081276 not found in FASTA\n",
            "[16474] NM_001081276 not found in FASTA\n",
            "[16475] NM_001081276 not found in FASTA\n",
            "[16476] NM_001081276 not found in FASTA\n",
            "[16477] NM_001081276 not found in FASTA\n",
            "[16478] NM_001081276 not found in FASTA\n",
            "[16479] NM_001081276 not found in FASTA\n",
            "[16480] NM_001081276 not found in FASTA\n",
            "[16481] NM_001081276 not found in FASTA\n",
            "[16482] NM_001081276 not found in FASTA\n",
            "[16483] NM_001081276 not found in FASTA\n",
            "[16484] NM_001081276 not found in FASTA\n",
            "[16485] NM_001081276 not found in FASTA\n",
            "[17355] NM_027896 not found in FASTA\n",
            "[17356] NM_027896 not found in FASTA\n",
            "[17357] NM_027896 not found in FASTA\n",
            "[17358] NM_027896 not found in FASTA\n",
            "[19563] NM_001128169 not found in FASTA\n",
            "[19564] NM_001128169 not found in FASTA\n",
            "[19565] NM_001128169 not found in FASTA\n",
            "[19566] NM_001128169 not found in FASTA\n",
            "[19932] NR_015456 not found in FASTA\n",
            "[19933] NR_015456 not found in FASTA\n",
            "[19934] NR_015456 not found in FASTA\n",
            "[19935] NR_015456 not found in FASTA\n",
            "[20951] NM_145975 not found in FASTA\n",
            "[20952] NM_145975 not found in FASTA\n",
            "[20953] NM_145975 not found in FASTA\n",
            "[20954] NM_145975 not found in FASTA\n",
            "[20955] NM_145975 not found in FASTA\n",
            "[20956] NM_145975 not found in FASTA\n",
            "[20957] NM_145975 not found in FASTA\n",
            "[20958] NM_145975 not found in FASTA\n",
            "[20959] NM_145975 not found in FASTA\n",
            "[20960] NM_145975 not found in FASTA\n",
            "[20961] NM_145975 not found in FASTA\n",
            "[20962] NM_145975 not found in FASTA\n",
            "[20963] NM_145975 not found in FASTA\n",
            "[20964] NM_145975 not found in FASTA\n",
            "[20965] NM_145975 not found in FASTA\n",
            "[20966] NM_145975 not found in FASTA\n",
            "[20967] NM_145975 not found in FASTA\n",
            "[20968] NM_145975 not found in FASTA\n",
            "[20969] NM_145975 not found in FASTA\n",
            "[20970] NM_145975 not found in FASTA\n",
            "[20971] NM_145975 not found in FASTA\n",
            "[20972] NM_145975 not found in FASTA\n",
            "[20973] NM_145975 not found in FASTA\n",
            "[20974] NM_145975 not found in FASTA\n",
            "[20975] NM_145975 not found in FASTA\n",
            "[20976] NM_145975 not found in FASTA\n",
            "[20977] NM_145975 not found in FASTA\n",
            "[20978] NM_145975 not found in FASTA\n",
            "[20979] NM_145975 not found in FASTA\n",
            "[20980] NM_145975 not found in FASTA\n",
            "[22085] NM_001145949 not found in FASTA\n",
            "[22086] NM_001145949 not found in FASTA\n",
            "[22087] NM_001145949 not found in FASTA\n",
            "[22088] NM_001145949 not found in FASTA\n",
            "[22089] NM_001145949 not found in FASTA\n",
            "[22090] NM_001145949 not found in FASTA\n",
            "[22091] NM_001145949 not found in FASTA\n",
            "[22092] NM_001145949 not found in FASTA\n",
            "[25820] NM_001003815 not found in FASTA\n",
            "[25821] NM_001003815 not found in FASTA\n",
            "[25822] NM_001003815 not found in FASTA\n",
            "[25823] NM_001003815 not found in FASTA\n",
            "[27003] NM_001172136 not found in FASTA\n",
            "[27004] NM_001172136 not found in FASTA\n",
            "[27707] NM_001030306 not found in FASTA\n",
            "[27708] NM_001030306 not found in FASTA\n",
            "[27709] NM_001030306 not found in FASTA\n",
            "[27710] NM_001030306 not found in FASTA\n",
            "[27711] NM_001030306 not found in FASTA\n",
            "[28068] NM_026143 not found in FASTA\n",
            "[28069] NM_026143 not found in FASTA\n",
            "[28070] NM_026143 not found in FASTA\n",
            "[28071] NM_026143 not found in FASTA\n",
            "[28072] NM_026143 not found in FASTA\n",
            "[28073] NM_026143 not found in FASTA\n",
            "[28074] NM_026143 not found in FASTA\n",
            "[28075] NM_026143 not found in FASTA\n",
            "[28076] NM_026143 not found in FASTA\n",
            "[28077] NM_026143 not found in FASTA\n",
            "[28078] NM_026143 not found in FASTA\n",
            "[28079] NM_026143 not found in FASTA\n",
            "[28080] NM_026143 not found in FASTA\n",
            "[28081] NM_026143 not found in FASTA\n",
            "[28082] NM_026143 not found in FASTA\n",
            "[28083] NM_026143 not found in FASTA\n",
            "[28084] NM_026143 not found in FASTA\n",
            "[28085] NM_026143 not found in FASTA\n",
            "[28086] NM_026143 not found in FASTA\n",
            "[28087] NM_026143 not found in FASTA\n",
            "[28088] NM_026143 not found in FASTA\n",
            "[29881] NM_008049 not found in FASTA\n",
            "[29882] NM_008049 not found in FASTA\n",
            "[29883] NM_008049 not found in FASTA\n",
            "[29884] NM_008049 not found in FASTA\n",
            "[29885] NM_008049 not found in FASTA\n",
            "[30805] NR_002840 not found in FASTA\n",
            "[30806] NR_002840 not found in FASTA\n",
            "[30807] NR_002840 not found in FASTA\n",
            "[30808] NR_002840 not found in FASTA\n",
            "[30809] NR_002840 not found in FASTA\n",
            "[30810] NR_002840 not found in FASTA\n",
            "[30811] NR_002840 not found in FASTA\n",
            "[30812] NR_002840 not found in FASTA\n",
            "[30813] NR_002840 not found in FASTA\n",
            "[30814] NR_002840 not found in FASTA\n",
            "[30815] NR_002840 not found in FASTA\n",
            "[30816] NR_002840 not found in FASTA\n",
            "[30817] NR_002840 not found in FASTA\n",
            "[30818] NR_002840 not found in FASTA\n",
            "[30819] NR_002840 not found in FASTA\n",
            "[30820] NR_002840 not found in FASTA\n",
            "[33173] NM_001083929 not found in FASTA\n",
            "[33174] NM_001083929 not found in FASTA\n",
            "[33839] NR_001592 not found in FASTA\n",
            "[33840] NR_001592 not found in FASTA\n",
            "[33841] NR_001592 not found in FASTA\n",
            "[33842] NR_001592 not found in FASTA\n",
            "[33843] NR_001592 not found in FASTA\n",
            "[33844] NR_001592 not found in FASTA\n",
            "[33845] NR_001592 not found in FASTA\n",
            "[33846] NR_001592 not found in FASTA\n",
            "[39973] NM_001081258 not found in FASTA\n",
            "[39974] NM_001081258 not found in FASTA\n",
            "[39975] NM_001081258 not found in FASTA\n",
            "[39976] NM_001081258 not found in FASTA\n",
            "[39977] NM_001081258 not found in FASTA\n",
            "[39978] NM_001081258 not found in FASTA\n",
            "[39979] NM_001081258 not found in FASTA\n",
            "[39980] NM_001081258 not found in FASTA\n",
            "[39981] NM_001081258 not found in FASTA\n",
            "[39982] NM_001081258 not found in FASTA\n",
            "[39983] NM_001081258 not found in FASTA\n",
            "[39984] NM_001081258 not found in FASTA\n",
            "[39985] NM_001081258 not found in FASTA\n",
            "[39986] NM_001081258 not found in FASTA\n",
            "[39987] NM_001081258 not found in FASTA\n",
            "[39988] NM_001081258 not found in FASTA\n",
            "[39989] NM_001081258 not found in FASTA\n",
            "[39990] NM_001081258 not found in FASTA\n",
            "[39991] NM_001081258 not found in FASTA\n",
            "[39992] NM_001081258 not found in FASTA\n",
            "[39993] NM_001081258 not found in FASTA\n",
            "[39994] NM_001081258 not found in FASTA\n",
            "[39995] NM_001081258 not found in FASTA\n",
            "[39996] NM_001081258 not found in FASTA\n",
            "[43983] NM_010760 not found in FASTA\n",
            "[43984] NM_010760 not found in FASTA\n",
            "[43985] NM_010760 not found in FASTA\n",
            "[43986] NM_010760 not found in FASTA\n",
            "[43987] NM_010760 not found in FASTA\n",
            "[44361] NM_001081357 not found in FASTA\n",
            "[44362] NM_001081357 not found in FASTA\n",
            "[44363] NM_001081357 not found in FASTA\n",
            "[44364] NM_001081357 not found in FASTA\n",
            "[44365] NM_001081357 not found in FASTA\n",
            "[44366] NM_001081357 not found in FASTA\n",
            "[44367] NM_001081357 not found in FASTA\n",
            "[44368] NM_001081357 not found in FASTA\n",
            "[44369] NM_001081357 not found in FASTA\n",
            "[45789] NM_027213 not found in FASTA\n",
            "[45790] NM_027213 not found in FASTA\n",
            "[45791] NM_027213 not found in FASTA\n",
            "[46838] NM_001081049 not found in FASTA\n",
            "[46839] NM_001081049 not found in FASTA\n",
            "[46840] NM_001081049 not found in FASTA\n",
            "[46841] NM_001081049 not found in FASTA\n",
            "[46842] NM_001081049 not found in FASTA\n",
            "[46843] NM_001081049 not found in FASTA\n",
            "[46844] NM_001081049 not found in FASTA\n",
            "[46845] NM_001081049 not found in FASTA\n",
            "[46846] NM_001081049 not found in FASTA\n",
            "[46847] NM_001081049 not found in FASTA\n",
            "[46848] NM_001081049 not found in FASTA\n",
            "[46849] NM_001081049 not found in FASTA\n",
            "[46850] NM_001081049 not found in FASTA\n",
            "[46851] NM_001081049 not found in FASTA\n",
            "[46852] NM_001081049 not found in FASTA\n",
            "[46853] NM_001081049 not found in FASTA\n",
            "[46854] NM_001081049 not found in FASTA\n",
            "[46855] NM_001081049 not found in FASTA\n",
            "[46856] NM_001081049 not found in FASTA\n",
            "[46857] NM_001081049 not found in FASTA\n",
            "[46858] NM_001081049 not found in FASTA\n",
            "[46859] NM_001081049 not found in FASTA\n",
            "[46860] NM_001081049 not found in FASTA\n",
            "[46861] NM_001081049 not found in FASTA\n",
            "[46862] NM_001081049 not found in FASTA\n",
            "[46863] NM_001081049 not found in FASTA\n",
            "[46864] NM_001081049 not found in FASTA\n",
            "[46865] NM_001081049 not found in FASTA\n",
            "[46866] NM_001081049 not found in FASTA\n",
            "[46867] NM_001081049 not found in FASTA\n",
            "[46868] NM_001081049 not found in FASTA\n",
            "[46869] NM_001081049 not found in FASTA\n",
            "[46870] NM_001081049 not found in FASTA\n",
            "[46871] NM_001081049 not found in FASTA\n",
            "[46872] NM_001081049 not found in FASTA\n",
            "[46873] NM_001081049 not found in FASTA\n",
            "[46874] NM_001081049 not found in FASTA\n",
            "[46875] NM_001081049 not found in FASTA\n",
            "[46876] NM_001081049 not found in FASTA\n",
            "[46877] NM_001081049 not found in FASTA\n",
            "[46878] NM_001081049 not found in FASTA\n",
            "[46879] NM_001081049 not found in FASTA\n",
            "[46880] NM_001081049 not found in FASTA\n",
            "[46881] NM_001081049 not found in FASTA\n",
            "[46882] NM_001081049 not found in FASTA\n",
            "[46883] NM_001081049 not found in FASTA\n",
            "[46884] NM_001081049 not found in FASTA\n",
            "[46885] NM_001081049 not found in FASTA\n",
            "[46886] NM_001081049 not found in FASTA\n",
            "[46887] NM_001081049 not found in FASTA\n",
            "[46888] NM_001081049 not found in FASTA\n",
            "[46889] NM_001081049 not found in FASTA\n",
            "[46890] NM_001081049 not found in FASTA\n",
            "[46891] NM_001081049 not found in FASTA\n",
            "[46892] NM_001081049 not found in FASTA\n",
            "[46893] NM_001081049 not found in FASTA\n",
            "[46894] NM_001081049 not found in FASTA\n",
            "[49585] NM_001081430 not found in FASTA\n",
            "[49586] NM_001081430 not found in FASTA\n",
            "[49587] NM_001081430 not found in FASTA\n",
            "[49588] NM_001081430 not found in FASTA\n",
            "[49589] NM_001081430 not found in FASTA\n",
            "[49590] NM_001081430 not found in FASTA\n",
            "[49591] NM_001081430 not found in FASTA\n",
            "[49592] NM_001081430 not found in FASTA\n",
            "[49593] NM_001081430 not found in FASTA\n",
            "[49594] NM_001081430 not found in FASTA\n",
            "[49595] NM_001081430 not found in FASTA\n",
            "[49596] NM_001081430 not found in FASTA\n",
            "[49597] NM_001081430 not found in FASTA\n",
            "[49598] NM_001081430 not found in FASTA\n",
            "[49790] NM_001146707 not found in FASTA\n",
            "[49791] NM_001146707 not found in FASTA\n",
            "[49792] NM_001146707 not found in FASTA\n",
            "[49793] NM_001146707 not found in FASTA\n",
            "[49794] NM_001146707 not found in FASTA\n",
            "[49795] NM_001146707 not found in FASTA\n",
            "[49796] NM_001146707 not found in FASTA\n",
            "[49797] NM_001146707 not found in FASTA\n",
            "[49798] NM_001146707 not found in FASTA\n",
            "[49799] NM_001146707 not found in FASTA\n",
            "[49800] NM_001146707 not found in FASTA\n",
            "[49801] NM_001146707 not found in FASTA\n",
            "[49802] NM_001146707 not found in FASTA\n",
            "[49803] NM_001146707 not found in FASTA\n",
            "[49804] NM_001146707 not found in FASTA\n",
            "[49805] NM_001146707 not found in FASTA\n",
            "[49806] NM_001146707 not found in FASTA\n",
            "[49807] NM_001146707 not found in FASTA\n",
            "[49808] NM_001146707 not found in FASTA\n",
            "[49809] NM_001146707 not found in FASTA\n",
            "[49810] NM_001146707 not found in FASTA\n",
            "[49811] NM_001146707 not found in FASTA\n",
            "[49812] NM_001146707 not found in FASTA\n",
            "[49813] NM_001146707 not found in FASTA\n",
            "[49814] NM_001146707 not found in FASTA\n",
            "[49815] NM_001146707 not found in FASTA\n",
            "[49816] NM_001146707 not found in FASTA\n",
            "[49817] NM_001146707 not found in FASTA\n",
            "[49818] NM_001146707 not found in FASTA\n",
            "[49819] NM_001146707 not found in FASTA\n",
            "[49820] NM_001146707 not found in FASTA\n",
            "[49821] NM_001146707 not found in FASTA\n",
            "[49822] NM_001146707 not found in FASTA\n",
            "[49823] NM_001146707 not found in FASTA\n",
            "[49824] NM_001146707 not found in FASTA\n",
            "[49825] NM_001146707 not found in FASTA\n",
            "[49826] NM_001146707 not found in FASTA\n",
            "[49827] NM_001146707 not found in FASTA\n",
            "[50465] NR_028086 not found in FASTA\n",
            "[50466] NR_028086 not found in FASTA\n",
            "[50973] NM_016743 not found in FASTA\n",
            "[50974] NM_016743 not found in FASTA\n",
            "[51871] NM_001081350 not found in FASTA\n",
            "[51872] NM_001081350 not found in FASTA\n",
            "[51873] NM_001081350 not found in FASTA\n",
            "[51874] NM_001081350 not found in FASTA\n",
            "[51875] NM_001081350 not found in FASTA\n",
            "[51876] NM_001081350 not found in FASTA\n",
            "[51877] NM_001081350 not found in FASTA\n",
            "[51878] NM_001081350 not found in FASTA\n",
            "[51879] NM_001081350 not found in FASTA\n",
            "[51880] NM_001081350 not found in FASTA\n",
            "[51881] NM_001081350 not found in FASTA\n",
            "[51882] NM_001081350 not found in FASTA\n",
            "[51883] NM_001081350 not found in FASTA\n",
            "[51884] NM_001081350 not found in FASTA\n",
            "[51885] NM_001081350 not found in FASTA\n",
            "[51886] NM_001081350 not found in FASTA\n",
            "[51887] NM_001081350 not found in FASTA\n",
            "[51888] NM_001081350 not found in FASTA\n",
            "[51889] NM_001081350 not found in FASTA\n",
            "[51890] NM_001081350 not found in FASTA\n",
            "[51891] NM_001081350 not found in FASTA\n",
            "[51892] NM_001081350 not found in FASTA\n",
            "[54108] NM_028091 not found in FASTA\n",
            "[54109] NM_028091 not found in FASTA\n",
            "[54110] NM_028091 not found in FASTA\n",
            "[54111] NM_028091 not found in FASTA\n",
            "[58459] NM_009089 not found in FASTA\n",
            "[58460] NM_009089 not found in FASTA\n",
            "[58461] NM_009089 not found in FASTA\n",
            "[58462] NM_009089 not found in FASTA\n",
            "[58463] NM_009089 not found in FASTA\n",
            "[58464] NM_009089 not found in FASTA\n",
            "[58465] NM_009089 not found in FASTA\n",
            "[58466] NM_009089 not found in FASTA\n",
            "[58467] NM_009089 not found in FASTA\n",
            "[58468] NM_009089 not found in FASTA\n",
            "[58469] NM_009089 not found in FASTA\n",
            "[58470] NM_009089 not found in FASTA\n",
            "[58471] NM_009089 not found in FASTA\n",
            "[58472] NM_009089 not found in FASTA\n",
            "[58473] NM_009089 not found in FASTA\n",
            "[58474] NM_009089 not found in FASTA\n",
            "[58475] NM_009089 not found in FASTA\n",
            "[58476] NM_009089 not found in FASTA\n",
            "[58477] NM_009089 not found in FASTA\n",
            "[58478] NM_009089 not found in FASTA\n",
            "[58479] NM_009089 not found in FASTA\n",
            "[58480] NM_009089 not found in FASTA\n",
            "[58481] NM_009089 not found in FASTA\n",
            "[58482] NM_009089 not found in FASTA\n",
            "[58483] NM_009089 not found in FASTA\n",
            "[58484] NM_009089 not found in FASTA\n",
            "[58485] NM_009089 not found in FASTA\n",
            "[58486] NM_009089 not found in FASTA\n",
            "[58487] NM_009089 not found in FASTA\n",
            "[58488] NM_009089 not found in FASTA\n",
            "[58489] NM_009089 not found in FASTA\n",
            "[58490] NM_009089 not found in FASTA\n",
            "[58491] NM_009089 not found in FASTA\n",
            "[58492] NM_009089 not found in FASTA\n",
            "[58493] NM_009089 not found in FASTA\n",
            "[58494] NM_009089 not found in FASTA\n",
            "[58495] NM_009089 not found in FASTA\n",
            "[58496] NM_009089 not found in FASTA\n",
            "[58497] NM_009089 not found in FASTA\n",
            "[58498] NM_009089 not found in FASTA\n",
            "[58499] NM_009089 not found in FASTA\n",
            "[58500] NM_009089 not found in FASTA\n",
            "[58501] NM_009089 not found in FASTA\n",
            "[58502] NM_009089 not found in FASTA\n",
            "[58503] NM_009089 not found in FASTA\n",
            "[58504] NM_009089 not found in FASTA\n",
            "[58505] NM_009089 not found in FASTA\n",
            "[58506] NM_009089 not found in FASTA\n",
            "[58507] NM_009089 not found in FASTA\n",
            "[58508] NM_009089 not found in FASTA\n",
            "[58509] NM_009089 not found in FASTA\n",
            "[58565] NM_027101 not found in FASTA\n",
            "[58566] NM_027101 not found in FASTA\n",
            "[58567] NM_027101 not found in FASTA\n",
            "[58568] NM_027101 not found in FASTA\n",
            "[58569] NM_027101 not found in FASTA\n",
            "[58570] NM_027101 not found in FASTA\n",
            "[59255] NM_175934 not found in FASTA\n",
            "[59256] NM_175934 not found in FASTA\n",
            "[59257] NM_175934 not found in FASTA\n",
            "[59258] NM_175934 not found in FASTA\n",
            "[59259] NM_175934 not found in FASTA\n",
            "[60818] NM_008943 not found in FASTA\n",
            "[60819] NM_008943 not found in FASTA\n",
            "[60820] NM_008943 not found in FASTA\n",
            "[60821] NM_008943 not found in FASTA\n",
            "[60822] NM_008943 not found in FASTA\n",
            "[60823] NM_008943 not found in FASTA\n",
            "[60824] NM_008943 not found in FASTA\n",
            "[60825] NM_008943 not found in FASTA\n",
            "[60826] NM_008943 not found in FASTA\n",
            "[60827] NM_008943 not found in FASTA\n",
            "[60828] NM_008943 not found in FASTA\n",
            "[60829] NM_008943 not found in FASTA\n",
            "[60830] NM_008943 not found in FASTA\n",
            "[60831] NM_008943 not found in FASTA\n",
            "[60832] NM_008943 not found in FASTA\n",
            "[60833] NM_008943 not found in FASTA\n",
            "[60834] NM_008943 not found in FASTA\n",
            "[63215] NM_177658 not found in FASTA\n",
            "[63216] NM_177658 not found in FASTA\n",
            "[63217] NM_177658 not found in FASTA\n",
            "[63218] NM_177658 not found in FASTA\n",
            "[63219] NM_177658 not found in FASTA\n",
            "[63220] NM_177658 not found in FASTA\n",
            "[63221] NM_177658 not found in FASTA\n",
            "[63222] NM_177658 not found in FASTA\n",
            "[63223] NM_177658 not found in FASTA\n",
            "[63224] NM_177658 not found in FASTA\n",
            "[63225] NM_177658 not found in FASTA\n",
            "[63226] NM_177658 not found in FASTA\n",
            "[63227] NM_177658 not found in FASTA\n",
            "[63228] NM_177658 not found in FASTA\n",
            "[63229] NM_177658 not found in FASTA\n",
            "[63230] NM_177658 not found in FASTA\n",
            "[63231] NM_177658 not found in FASTA\n",
            "[63232] NM_177658 not found in FASTA\n",
            "[63233] NM_177658 not found in FASTA\n",
            "[63234] NM_177658 not found in FASTA\n",
            "[63235] NM_177658 not found in FASTA\n",
            "[63236] NM_177658 not found in FASTA\n",
            "[63237] NM_177658 not found in FASTA\n",
            "[63238] NM_177658 not found in FASTA\n",
            "[64753] NM_009051 not found in FASTA\n",
            "[64754] NM_009051 not found in FASTA\n",
            "[64755] NM_009051 not found in FASTA\n",
            "[64756] NM_009051 not found in FASTA\n",
            "[64757] NM_009051 not found in FASTA\n",
            "[64758] NM_009051 not found in FASTA\n",
            "[65245] NM_001081013 not found in FASTA\n",
            "[65246] NM_001081013 not found in FASTA\n",
            "[65247] NM_001081013 not found in FASTA\n",
            "[65248] NM_001081013 not found in FASTA\n",
            "[65249] NM_001081013 not found in FASTA\n",
            "[65250] NM_001081013 not found in FASTA\n",
            "[65251] NM_001081013 not found in FASTA\n",
            "[65252] NM_001081013 not found in FASTA\n",
            "[65253] NM_001081013 not found in FASTA\n",
            "[65254] NM_001081013 not found in FASTA\n",
            "[65255] NM_001081013 not found in FASTA\n",
            "[65256] NM_001081013 not found in FASTA\n",
            "[65257] NM_001081013 not found in FASTA\n",
            "완료! 저장 위치: /content/drive/MyDrive/term_project/binding_windows_-10+10.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crosslinked base 열을 이용해서 제대로 sequence를 뽑아냈는지 검증"
      ],
      "metadata": {
        "id": "vwYCkX3C7vOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "\n",
        "# 경로 설정\n",
        "project_path = \"/content/drive/MyDrive/term_project/\"\n",
        "\n",
        "# Excel 파일 읽기\n",
        "binding_sites = pd.read_excel(f\"{project_path}Lin28a_binding.xls\", header=1)\n",
        "\n",
        "# transcript별 binding site 개수 세기\n",
        "site_counts = binding_sites[\"Transcript\"].value_counts()\n",
        "\n",
        "# 2개 이상인 transcript만 남김\n",
        "multi_site_transcripts = site_counts[site_counts >= 2].index\n",
        "\n",
        "# binding site가 1개뿐인 transcript 제거\n",
        "binding_sites = binding_sites[binding_sites[\"Transcript\"].isin(multi_site_transcripts)]\n",
        "\n",
        "# FASTA 파싱\n",
        "fasta_file = f\"{project_path}refMrna.fa\"\n",
        "transcripts = {}\n",
        "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "    fasta_id = record.description.split()[0]\n",
        "    fasta_id_short = fasta_id.split('.')[0]\n",
        "    transcripts[fasta_id_short] = record.seq\n",
        "\n",
        "# 검증: window 중앙 염기 == Crosslinked base ?\n",
        "mismatches = []\n",
        "\n",
        "for idx, row in binding_sites.iterrows():\n",
        "    transcript_id = row[\"Transcript\"]\n",
        "    transcript_id_short = transcript_id.split('.')[0]\n",
        "\n",
        "    if transcript_id_short not in transcripts:\n",
        "        # FASTA에 없으면 기록\n",
        "        mismatches.append({\n",
        "            \"RowIdx\": idx,\n",
        "            \"Transcript\": transcript_id,\n",
        "            \"Position\": row[\"Position\"],\n",
        "            \"Expected\": row[\"Crosslinked base\"],\n",
        "            \"Found\": \"NOT_FOUND\",\n",
        "            \"WindowSeq\": \"\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    pos = int(row[\"Position\"])  # 0-based index\n",
        "    seq = transcripts[transcript_id_short]\n",
        "\n",
        "    # window 계산\n",
        "    start = max(0, pos - 10)\n",
        "    end = min(len(seq), pos + 10 + 1)\n",
        "    window_seq = seq[start:end]\n",
        "\n",
        "    if len(window_seq) == 0:\n",
        "        # 비어있는 시퀀스라면 기록\n",
        "        mismatches.append({\n",
        "            \"RowIdx\": idx,\n",
        "            \"Transcript\": transcript_id,\n",
        "            \"Position\": row[\"Position\"],\n",
        "            \"Expected\": row[\"Crosslinked base\"],\n",
        "            \"Found\": \"EMPTY\",\n",
        "            \"WindowSeq\": \"\"\n",
        "        })\n",
        "        continue\n",
        "\n",
        "    # 중앙 염기 index 계산\n",
        "    center_idx = (len(window_seq) - 1) // 2\n",
        "    center_base = window_seq[center_idx]\n",
        "\n",
        "    # crosslinked base와 비교 (대소문자 무시)\n",
        "    crosslinked_base = row[\"Crosslinked base\"]\n",
        "    if center_base.upper() != crosslinked_base.upper():\n",
        "        mismatches.append({\n",
        "            \"RowIdx\": idx,\n",
        "            \"Transcript\": transcript_id,\n",
        "            \"Position\": row[\"Position\"],\n",
        "            \"Expected\": crosslinked_base,\n",
        "            \"Found\": center_base,\n",
        "            \"WindowSeq\": str(window_seq)\n",
        "        })\n",
        "\n",
        "# 결과 출력\n",
        "if mismatches:\n",
        "    mismatch_df = pd.DataFrame(mismatches)\n",
        "    print(\"⚠️ 중앙 염기 불일치/누락 사례:\")\n",
        "    print(mismatch_df)\n",
        "    print(\"\\n🔍 총 중앙 염기 불일치/누락 사례 수:\", len(mismatch_df))\n",
        "\n",
        "    # CSV로 저장\n",
        "    output_file = f\"{project_path}mismatch_report.csv\"\n",
        "    mismatch_df.to_csv(output_file, index=False)\n",
        "    print(\"📂 mismatch_report.csv 로 저장 완료:\", output_file)\n",
        "else:\n",
        "    print(\"✅ 모든 window의 중앙 염기가 Crosslinked base와 일치합니다!\")"
      ],
      "metadata": {
        "id": "GUxk3RB3kSst",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792783ed-2bd7-4653-d9f4-f03aaa3331ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ 중앙 염기 불일치/누락 사례:\n",
            "       RowIdx    Transcript  Position Expected Found              WindowSeq\n",
            "0          20  NM_001013608       522        G     a  tcccagatcgaaaaattccat\n",
            "1          21  NM_001013608       601        G     c  taggtacttgcgagattacca\n",
            "2          23  NM_001013608       851        G     t  cctctttctgtcctctacaac\n",
            "3          24  NM_001013608       879        G     t  atgaattggatacctggggat\n",
            "4          25  NM_001013608       922        G     a  cggtagcaaaaaagacaatga\n",
            "...       ...           ...       ...      ...   ...                    ...\n",
            "14039   65469     NM_207623      2548        G     t  ctagagagggttcctgttttg\n",
            "14040   65470     NM_207623      2550        G     c  agagagggttcctgttttgaa\n",
            "14041   65471     NM_207623      2741        G     a  agtcatgtttaatagctatca\n",
            "14042   65532     NM_027445       197        G     t  aacatttctttcaaccggcct\n",
            "14043   65533     NM_027445       334        G     t  ttgaggtttctcctacccttc\n",
            "\n",
            "[14044 rows x 6 columns]\n",
            "\n",
            "🔍 총 중앙 염기 불일치/누락 사례 수: 14044\n",
            "📂 mismatch_report.csv 로 저장 완료: /content/drive/MyDrive/term_project/mismatch_report.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "각 전사체마다 position별로 mismatch 여부를 기록\n",
        "\n",
        "mismatch가 1건이라도 있으면 \"정상적으로 뽑아내지 못한\" 전사체로 간주\n",
        "\n",
        "최종적으로 mismatch가 전혀 없는 전사체의 window 정보를 새 CSV로 저장"
      ],
      "metadata": {
        "id": "IE8pxmb7Nv2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 전사체별 mismatch 여부 집계\n",
        "# transcript_id_short 기준으로 mismatch 여부를 저장할 딕셔너리 초기화\n",
        "transcript_mismatch_flags = {}\n",
        "\n",
        "for mismatch in mismatches:\n",
        "    transcript_id_short = mismatch[\"Transcript\"].split('.')[0]\n",
        "    transcript_mismatch_flags[transcript_id_short] = True\n",
        "\n",
        "# 모든 전사체 ID를 먼저 True로 초기화 (추후에 mismatch 없으면 False로 갱신)\n",
        "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
        "    fasta_id_short = record.description.split()[0].split('.')[0]\n",
        "    if fasta_id_short not in transcript_mismatch_flags:\n",
        "        transcript_mismatch_flags[fasta_id_short] = False\n",
        "\n",
        "# ✅ mismatch 없는 전사체만 추출\n",
        "no_mismatch_transcripts = {tid for tid, has_mismatch in transcript_mismatch_flags.items() if not has_mismatch}\n",
        "print(\"\\n✅ mismatch 없는 전사체 수:\", len(no_mismatch_transcripts))\n",
        "\n",
        "# ✅ window 정보에서 mismatch 없는 전사체만 필터링\n",
        "windows_df = pd.DataFrame(windows)\n",
        "windows_clean_df = windows_df[windows_df[\"Transcript\"].apply(lambda tid: tid.split('.')[0] in no_mismatch_transcripts)]\n",
        "\n",
        "# ✅ 결과 저장\n",
        "output_clean_file = f\"{project_path}windows_clean_transcripts_only.csv\"\n",
        "windows_clean_df.to_csv(output_clean_file, index=False)\n",
        "print(\"📂 mismatch 없는 전사체의 window 정보 저장 완료:\", output_clean_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcsf1po5Nud3",
        "outputId": "89ad6b2d-b571-4985-de95-40c39bc7b301"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ mismatch 없는 전사체 수: 41389\n",
            "📂 mismatch 없는 전사체의 window 정보 저장 완료: /content/drive/MyDrive/term_project/windows_clean_transcripts_only.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ window 길이가 21이 아닌 row 제거\n",
        "windows_clean_df = windows_clean_df[windows_clean_df[\"WindowSeq\"].apply(len) == 21].reset_index(drop=True)\n",
        "\n",
        "print(\"✅ 길이가 21인 window만 남겼습니다. 최종 데이터셋 크기:\", len(windows_clean_df))\n",
        "\n",
        "# ✅ (선택) 결과 CSV로 다시 저장 (같은 파일 덮어쓰기)\n",
        "windows_clean_df.to_csv(output_clean_file, index=False)\n",
        "print(\"📂 길이 정제된 데이터셋 저장 완료:\", output_clean_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243aP_rkZczV",
        "outputId": "b4a959d5-4215-45aa-ea17-be0eaeba8325"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 길이가 21인 window만 남겼습니다. 최종 데이터셋 크기: 44932\n",
            "📂 길이 정제된 데이터셋 저장 완료: /content/drive/MyDrive/term_project/windows_clean_transcripts_only.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🟩 정리: 최종 목표\n",
        "✅ 목표:\n",
        "주어진 window sequence가 LIN28a binding site인지 여부를 예측하는 binary classifier.\n",
        "\n",
        "✅ 데이터셋 구성:\n",
        "1️⃣ Positive set\n",
        "\n",
        "windows_clean_transcripts_only.csv → LIN28a binding site sequences (label = 1)\n",
        "\n",
        "2️⃣ Negative set\n",
        "\n",
        "같은 길이의 random sequence (binding site 아님, label = 0)\n",
        "\n",
        "데이터 수: positive set과 동일한 수로 생성\n",
        "\n",
        "3️⃣ 두 세트를 합쳐서 (same size), 적절히 섞음 (shuffle)\n",
        "4️⃣ train / validation / test dataset으로 나누기 (보통 70/15/15 또는 80/10/10)"
      ],
      "metadata": {
        "id": "uhrJdDEoRNBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1. positive data set\n",
        "positive_df = windows_clean_df.copy()\n",
        "positive_df[\"Label\"] = 1\n",
        "\n",
        "# ✅ 2. negative data set 만들기\n",
        "import random\n",
        "\n",
        "def random_seq(length=21):\n",
        "    return ''.join(random.choices(['A', 'T', 'G', 'C'], k=length))\n",
        "\n",
        "negative_data = [random_seq(21) for _ in range(len(positive_df))]\n",
        "\n",
        "# ✅ 3. negative data frame\n",
        "negative_df = pd.DataFrame({\n",
        "    \"WindowSeq\": negative_data,\n",
        "    \"Label\": 0\n",
        "})\n",
        "\n",
        "# ✅ 4. 두 개 합치고 shuffle\n",
        "full_df = pd.concat([positive_df[[\"WindowSeq\", \"Label\"]], negative_df], ignore_index=True)\n",
        "full_df = full_df.sample(frac=1).reset_index(drop=True)  # shuffle\n",
        "\n",
        "print(\"전체 데이터셋 크기:\", len(full_df))\n",
        "\n",
        "# ✅ 5. Train/Validation/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train+valid / test 나누기 (예: 85/15)\n",
        "train_valid_df, test_df = train_test_split(full_df, test_size=0.15, random_state=42, stratify=full_df[\"Label\"])\n",
        "\n",
        "# train / valid 나누기 (예: 80/20 of train_valid)\n",
        "train_df, valid_df = train_test_split(train_valid_df, test_size=0.176, random_state=42, stratify=train_valid_df[\"Label\"])\n",
        "\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Valid size:\", len(valid_df))\n",
        "print(\"Test size:\", len(test_df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMTBNUGwSD_e",
        "outputId": "ecdfe617-91e2-4ea3-a911-cf906ed59436"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터셋 크기: 89864\n",
            "Train size: 62940\n",
            "Valid size: 13444\n",
            "Test size: 13480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train 데이터 샘플:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"Valid 데이터 샘플:\")\n",
        "print(valid_df.head())\n",
        "\n",
        "print(\"Test 데이터 샘플:\")\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_o0OFkmSQuK",
        "outputId": "fb0d4fc5-efae-497e-bc9b-f396d00629c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train 데이터 샘플:\n",
            "                   WindowSeq  Label\n",
            "3196   gaccgctcccaggggggcagc      1\n",
            "7118   cctcccacttcttaaaagtga      1\n",
            "77741  TCGCCACTCACGCCACTTGCC      0\n",
            "32773  CTGGAACCTGGACGGTGGGCT      0\n",
            "36289  GGCATTAACGCCGTCTATATT      0\n",
            "Valid 데이터 샘플:\n",
            "                   WindowSeq  Label\n",
            "25960  agttggaccaagaggaaatct      1\n",
            "12319  CTACCATCGGGCTTCCCCTTC      0\n",
            "39581  ctttagctggggagatgggga      1\n",
            "24841  AAGCACCGCGGTTAGATCGTA      0\n",
            "75448  atagtaaggttgtgttacttt      1\n",
            "Test 데이터 샘플:\n",
            "                   WindowSeq  Label\n",
            "11638  GCCCGTACACGAAGTAGGCTT      0\n",
            "51931  ctcgactgtgagatgtcctac      1\n",
            "37282  aagacaattaagtgaagtgtc      1\n",
            "81954  tagagcctcccgcagaggatc      1\n",
            "22462  CCCATCGTTGATCTCCCAAAA      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 보니까 positive data set은 소문자, negative data set은 대문자로 되어있음.\n",
        "# 대문자로 통합\n",
        "\n",
        "# 통합 데이터셋에서 대문자로 변환\n",
        "full_df[\"WindowSeq\"] = full_df[\"WindowSeq\"].str.upper()\n",
        "\n",
        "# 그리고 나눠진 데이터셋에도 반영\n",
        "train_df[\"WindowSeq\"] = train_df[\"WindowSeq\"].str.upper()\n",
        "valid_df[\"WindowSeq\"] = valid_df[\"WindowSeq\"].str.upper()\n",
        "test_df[\"WindowSeq\"] = test_df[\"WindowSeq\"].str.upper()"
      ],
      "metadata": {
        "id": "oE8Zkph-TJpw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HMM으로 만든 인공 데이터셋에 적용안되는 문제가 있어서 일반화하기 위해서 앞 뒤로 랜덤하게 3nt 자르기\n",
        "\n",
        "def random_crop_to_18(seq):\n",
        "    # seq: 길이 21인 문자열\n",
        "    assert len(seq) == 21, f\"Expected 21nt, got {len(seq)}\"\n",
        "    start = np.random.randint(0, 4)  # 0, 1, 2, 3 중 하나 선택\n",
        "    return seq[start:start+18]\n"
      ],
      "metadata": {
        "id": "NrRRoSgQqYs2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 21nt → 18nt로 자르기\n",
        "full_df[\"WindowSeq\"] = full_df[\"WindowSeq\"].apply(random_crop_to_18)\n",
        "train_df[\"WindowSeq\"] = train_df[\"WindowSeq\"].apply(random_crop_to_18)\n",
        "valid_df[\"WindowSeq\"] = valid_df[\"WindowSeq\"].apply(random_crop_to_18)\n",
        "test_df[\"WindowSeq\"]  = test_df[\"WindowSeq\"].apply(random_crop_to_18)"
      ],
      "metadata": {
        "id": "pv-nlk66qlEf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset은 다 준비되었으니 이제 이걸로 CNN 모델 학습"
      ],
      "metadata": {
        "id": "GooROH51YH5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Dataset & DataLoader\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "BASE2IDX = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
        "\n",
        "def one_hot_encode(seq):\n",
        "    tensor = torch.zeros((len(seq), 4))\n",
        "    for i, base in enumerate(seq):\n",
        "        if base in BASE2IDX:\n",
        "            tensor[i, BASE2IDX[base]] = 1\n",
        "    return tensor\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.seqs = df[\"WindowSeq\"].values\n",
        "        self.labels = df[\"Label\"].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq_tensor = one_hot_encode(self.seqs[idx])\n",
        "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "        return seq_tensor, label\n"
      ],
      "metadata": {
        "id": "vPRk_I13YM6Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataset = SeqDataset(train_df)\n",
        "valid_dataset = SeqDataset(valid_df)\n",
        "test_dataset = SeqDataset(test_df)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "S8VsJWPMYPw5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1D CNN 모델 정의\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class Simple1DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv1d(4, 32, kernel_size=5, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.Conv1d(32, 64, kernel_size=5, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2)\n",
        "        )\n",
        "        self.fc = nn.Linear(64 * 3, 1)  # (sequence length // 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch, 21, 4) → (batch, 4, 21)\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return torch.sigmoid(self.fc(x)).squeeze(1)\n"
      ],
      "metadata": {
        "id": "3qIP8d9uYTD2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Simple1DCNN().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for seqs, labels in train_loader:\n",
        "        seqs, labels = seqs.to(device), labels.to(device)\n",
        "        preds = model(seqs.float())\n",
        "        loss = criterion(preds, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * seqs.size(0)\n",
        "        correct += ((preds > 0.5).float() == labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    acc = correct / len(train_loader.dataset) * 100\n",
        "    print(f\"Epoch {epoch}: loss={train_loss:.4f}, acc={acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFfdWWo2YWrA",
        "outputId": "f16afaf2-f500-48fe-cd8d-e956e846c26e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss=0.4138, acc=81.58%\n",
            "Epoch 1: loss=0.3655, acc=84.32%\n",
            "Epoch 2: loss=0.3570, acc=84.69%\n",
            "Epoch 3: loss=0.3512, acc=84.88%\n",
            "Epoch 4: loss=0.3471, acc=85.07%\n",
            "Epoch 5: loss=0.3437, acc=85.25%\n",
            "Epoch 6: loss=0.3405, acc=85.30%\n",
            "Epoch 7: loss=0.3369, acc=85.51%\n",
            "Epoch 8: loss=0.3347, acc=85.68%\n",
            "Epoch 9: loss=0.3323, acc=85.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Valid/Test 평가\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for seqs, labels in loader:\n",
        "            seqs, labels = seqs.to(device), labels.to(device)\n",
        "            preds = model(seqs.float())\n",
        "            correct += ((preds > 0.5).float() == labels).sum().item()\n",
        "    return correct / len(loader.dataset) * 100\n",
        "\n",
        "train_acc = evaluate(train_loader)\n",
        "test_acc = evaluate(test_loader)\n",
        "\n",
        "print(f\"Train Accuracy: {train_acc:.2f}%\")\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34id_5L6YZ9p",
        "outputId": "ac127a7e-b9a6-41f8-b8d0-8ae8f5161c07"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 86.00%\n",
            "Test Accuracy: 84.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 예: Simple1DCNN 모델을 저장\n",
        "torch.save(model.state_dict(), \"model.pt\")"
      ],
      "metadata": {
        "id": "sOB83UgQgdAX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 논문에 나온 HMM을 이용해서 만든 인공 dataset을 만들어\n",
        "CNN을 통해 만들 preditor를 평가"
      ],
      "metadata": {
        "id": "qYDf7_pWcqls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 염기 목록 (U는 마지막에 T로 바뀜)\n",
        "bases = [\"A\", \"C\", \"G\", \"U\"]\n",
        "\n",
        "# ✅ Emission matrix (Table S7E 기반, 상태 0~18; 상태 0은 dummy)\n",
        "emission_matrix = {\n",
        "    \"A\": [0, 0.271, 0.254, 0.168, 0.121, 0.155, 0.091, 0.522, 0.585, 0.002, 0.308, 0.281, 0.152, 0.146, 0.091, 0.138, 0.172, 0.197, 0.231],\n",
        "    \"C\": [0, 0.170, 0.098, 0.055, 0.045, 0.032, 0.091, 0.078, 0.061, 0.000, 0.086, 0.031, 0.051, 0.054, 0.065, 0.081, 0.089, 0.103, 0.168],\n",
        "    \"G\": [0, 0.214, 0.137, 0.112, 0.117, 0.072, 0.111, 0.130, 0.069, 0.940, 0.286, 0.488, 0.369, 0.121, 0.109, 0.100, 0.109, 0.170, 0.235],\n",
        "    \"U\": [0, 0.248, 0.186, 0.144, 0.104, 0.105, 0.158, 0.123, 0.253, 0.001, 0.243, 0.110, 0.112, 0.137, 0.130, 0.116, 0.139, 0.168, 0.189],\n",
        "}\n",
        "\n",
        "# ✅ Transition matrix (Table S7D 기반, 상태 0: S → 1)\n",
        "transition_matrix = np.array([\n",
        "    [0.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # from S (0)\n",
        "    [0, 0.302, 0.698, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0.099, 0.901, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0.085, 0.915, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0.097, 0.903, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0.110, 0.890, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0.091, 0.908, 0, 0, 0.001, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0.064, 0.934, 0, 0.001, 0.001, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0.098, 0.898, 0, 0, 0.001, 0, 0.002, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0.004, 0.990, 0, 0, 0.001, 0, 0.006, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.980, 0, 0.001, 0.017, 0.002, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0],\n",
        "    [0.006, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.994, 0, 0.001],\n",
        "    [0.012, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.988, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.001, 0.999],\n",
        "    [0.988, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.012]\n",
        "])\n",
        "\n",
        "# ✅ 랜덤 염기 생성 함수\n",
        "def random_base():\n",
        "    return np.random.choice([\"A\", \"T\", \"G\", \"C\"])\n",
        "\n",
        "# ✅ random negative 시퀀스\n",
        "def generate_random_seq(length=18):\n",
        "    return ''.join(random_base() for _ in range(length))\n",
        "\n",
        "# ✅ HMM 기반 motif 시퀀스 생성\n",
        "def generate_motif_fixed():\n",
        "    state = 1  # 시작 상태\n",
        "    motif = \"\"\n",
        "\n",
        "    while len(motif) < 18:\n",
        "        # emission sampling\n",
        "        probs = np.array([emission_matrix[b][state] for b in bases])\n",
        "        total = probs.sum()\n",
        "        if total == 0:\n",
        "            base = random_base()\n",
        "        else:\n",
        "            probs /= total\n",
        "            base = np.random.choice(bases, p=probs)\n",
        "        motif += base\n",
        "\n",
        "        # transition sampling\n",
        "        probs = transition_matrix[state]\n",
        "        total = probs.sum()\n",
        "        if total == 0:\n",
        "            break\n",
        "        probs = probs / total\n",
        "        state = np.random.choice(range(19), p=probs)\n",
        "\n",
        "    # motif 길이 보정\n",
        "    if len(motif) < 18:\n",
        "        motif += ''.join(random_base() for _ in range(18 - len(motif)))\n",
        "    elif len(motif) > 18:\n",
        "        motif = motif[:18]\n",
        "\n",
        "    return motif.replace(\"U\", \"T\")\n",
        "\n",
        "# ✅ 데이터 생성\n",
        "positive_data_HMM = [generate_motif_fixed() for _ in range(1000)]\n",
        "negative_data_HMM = [generate_random_seq() for _ in range(1000)]\n",
        "\n",
        "# ✅ DataFrame 생성\n",
        "df_positive_HMM = pd.DataFrame({\"WindowSeq\": positive_data_HMM, \"Label\": 1})\n",
        "df_negative_HMM = pd.DataFrame({\"WindowSeq\": negative_data_HMM, \"Label\": 0})\n",
        "\n",
        "# ✅ 합치고 셔플\n",
        "test_df_HMM = pd.concat([df_positive_HMM, df_negative_HMM], ignore_index=True)\n",
        "test_df_HMM = test_df_HMM.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# ✅ 9번째 염기가 G인 비율 확인\n",
        "is_g_at_9th = df_positive_HMM[\"WindowSeq\"].str[8] == \"G\"\n",
        "g_ratio = is_g_at_9th.mean()\n",
        "print(f\"9번째 염기가 G인 비율: {g_ratio:.4f} ({g_ratio * 100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqrJsWgVf1yM",
        "outputId": "d06383bb-e4fb-4335-ea6f-7362d83ee15c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9번째 염기가 G인 비율: 0.4280 (42.80%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positive 샘플 몇 개 보기\n",
        "print(\"✅ Positive 샘플 예시:\")\n",
        "print(df_positive_HMM.head())\n",
        "\n",
        "# Negative 샘플 몇 개 보기\n",
        "print(\"\\n✅ Negative 샘플 예시:\")\n",
        "print(df_negative_HMM.head())\n",
        "\n",
        "# 전체 test_df에서 상위 10개만 확인\n",
        "print(\"\\n✅ 섞인 전체 Test Dataset 예시:\")\n",
        "print(test_df_HMM.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxMXAcVPtjVk",
        "outputId": "3bbe6c73-974b-444d-f4c4-aa1e3e3ae346"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Positive 샘플 예시:\n",
            "            WindowSeq  Label\n",
            "0  CAAAAAAAGTAGCTAGGG      1\n",
            "1  TTGACAGGGGGGAAGAGC      1\n",
            "2  ACTAGCAAGGTGACATTA      1\n",
            "3  AAAAAAGAAAGAGGGTCC      1\n",
            "4  ACTAATAATTGGGGTGTA      1\n",
            "\n",
            "✅ Negative 샘플 예시:\n",
            "            WindowSeq  Label\n",
            "0  CGCACATCTGATGTGGGT      0\n",
            "1  GTCACGATATGGAGAACA      0\n",
            "2  TAAGCGAATGGAAGAAAC      0\n",
            "3  GCTGTGGAAAGGAGTAGA      0\n",
            "4  TGTGCACGCCTAAGTCTT      0\n",
            "\n",
            "✅ 섞인 전체 Test Dataset 예시:\n",
            "            WindowSeq  Label\n",
            "0  ATGGCTGTTTAGCTGAGC      0\n",
            "1  TAGGTTATGAGAGTAAGA      1\n",
            "2  CAGTTCTCAGTTACCAGT      0\n",
            "3  ATAGTAGTTAGAGTTCAT      1\n",
            "4  CCTAAGTATCATTGTCGT      0\n",
            "5  TCATTCGAACGAGAGACA      0\n",
            "6  GGTTTCAATGTAAGGTAC      1\n",
            "7  CACAACAGTACGATGGAA      0\n",
            "8  GTCCTGGAAAGAGGGTTC      1\n",
            "9  CAGGCCGTATTTGGCTTC      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 평가용 DataLoader\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.seqs = df[\"WindowSeq\"].values\n",
        "        self.labels = df[\"Label\"].values.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.seqs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.seqs[idx]\n",
        "        onehot = seq_to_onehot(seq)\n",
        "        label = self.labels[idx]\n",
        "        return torch.tensor(onehot), torch.tensor(label)\n",
        "\n",
        "# One-hot 변환 함수\n",
        "def seq_to_onehot(seq):\n",
        "    base_dict = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
        "    onehot = np.zeros((len(seq), 4), dtype=np.float32)\n",
        "    for i, base in enumerate(seq):\n",
        "        if base in base_dict:\n",
        "            onehot[i, base_dict[base]] = 1.0\n",
        "    return onehot\n",
        "\n",
        "# Test Dataset & DataLoader\n",
        "test_dataset = SeqDataset(test_df_HMM)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "325FAReNfaKk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 로드 & 평가\n",
        "\n",
        "# 2️⃣ CNN 모델 불러오기\n",
        "model = Simple1DCNN()\n",
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 평가\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for seqs, labels in test_loader:\n",
        "        seqs, labels = seqs.to(device), labels.to(device)\n",
        "        preds = model(seqs.float())\n",
        "        correct += ((preds > 0.5).float() == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_acc = correct / total * 100\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzrCoHgtfvnr",
        "outputId": "93d9691b-d2ec-41d4-fc05-0b7521316e17"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 73.55%\n"
          ]
        }
      ]
    }
  ]
}